{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p_qf4srw4QZ"
   },
   "source": [
    "CIFAR10 is a 60,000 images dataset where each image is of shape 32* 32 *3 (height, width, depth). \n",
    "- Depth =3, because the images are colored - RGB (3 colors). \n",
    "- We need to classify images based on 10 classes.\n",
    "So it's a multi class classification problem in deep learning.\n",
    "- We will split the data, 50,000 and 10,000 for training and testing respectively. \n",
    "- We will follow a Multi-Model approch and then identify which is the best one for our dataset. (starting from self made Dense Neural Networks to Pretrained Neural Networks including Finetuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOYn7zGNwg0J"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv4TyX5U8_rs"
   },
   "source": [
    "Create a baseline Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EaXCMCVMivr"
   },
   "outputs": [],
   "source": [
    "def plain_dense_neural_network(height, width, depth, classes):\n",
    "  model = tf.keras.models.Sequential([\n",
    "   tf.keras.layers.Flatten(input_shape=(height, width, depth)),\n",
    "   tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "   tf.keras.layers.Dense(classes, activation=tf.nn.softmax )                               \n",
    "  ])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybQVQ8BdwzqH"
   },
   "outputs": [],
   "source": [
    "def dense_neural_network_with_dropout(height, width, depth, classes):\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "                                        layers.Flatten(input_shape =(height, width,depth)),\n",
    "                                        layers.Dense(1024, tf.nn.relu),\n",
    "                                        layers.Dropout(0.2),\n",
    "                                        layers.Dense(512, tf.nn.relu),\n",
    "                                        layers.Dropout(0.2),\n",
    "                                        layers.Dense(10, tf.nn.softmax)\n",
    "                                      ])\n",
    "    model.compile(optimizer='adam', loss ='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrnV-4hsO7SV"
   },
   "source": [
    "Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rHWJuDYOapf"
   },
   "outputs": [],
   "source": [
    "def simple_vgg_based_arch_with_maxpool(height, width, depth, classes):\n",
    "  initial_filters = 32\n",
    "  filter_shape=(3,3)\n",
    "  padding = \"same\"\n",
    "  pool_size = (2,2)\n",
    "  dropout_rate = 0.25\n",
    "  model = tf.keras.models.Sequential([\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.MaxPooling2D(pool_size),\n",
    "                                    \n",
    "\n",
    "                                      keras.layers.Conv2D(64, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.MaxPooling2D(pool_size),\n",
    "                                      \n",
    "\n",
    "                                      keras.layers.Flatten(),\n",
    "                                      keras.layers.Dense(512, activation='relu'),\n",
    "                                  \n",
    "\n",
    "                                      keras.layers.Dense(classes, activation='softmax')\n",
    "\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLFqpdr8UpLH"
   },
   "outputs": [],
   "source": [
    "def simple_vgg_based_arch_with_maxpool_and_dropout(height, width, depth, classes):\n",
    "  initial_filters = 32\n",
    "  filter_shape=(3,3)\n",
    "  padding = \"same\"\n",
    "  pool_size = (2,2)\n",
    "  dropout_rate = 0.25\n",
    "  model = tf.keras.models.Sequential([\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.MaxPooling2D(pool_size),\n",
    "                                      keras.layers.SpatialDropout2D(dropout_rate),\n",
    "\n",
    "                                      keras.layers.Conv2D(64, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.Conv2D(initial_filters, filter_shape, padding=padding, input_shape=(height, width, depth), activation='relu'),\n",
    "                                      keras.layers.MaxPooling2D(pool_size),\n",
    "                                      keras.layers.SpatialDropout2D(dropout_rate),\n",
    "\n",
    "                                      keras.layers.Flatten(),\n",
    "                                      keras.layers.Dense(512, activation='relu'),\n",
    "                                      keras.layers.Dropout(0.5),\n",
    "\n",
    "                                      keras.layers.Dense(classes, activation='softmax')\n",
    "\n",
    "  ])\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgoFptQPcsQn"
   },
   "outputs": [],
   "source": [
    "def feature_extraction_using_pretrained_vgg16Model(height, width, depth, classes, X_train, X_test):\n",
    "    \n",
    "    # creating the base model of pre-trained VGG16 model\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape =(width, height,depth))\n",
    "    \n",
    "    # extracting features for training frames\n",
    "    X_train = base_model.predict(X_train)\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    # extracting features for validation frames\n",
    "    X_test = base_model.predict(X_test)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    # reshaping the training as well as validation frames in single dimension\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    # Now we have obtained our new dataset, which can be used for another off-the-shelf Classifier like Random Forest\n",
    "    num_trees = 200\n",
    "    model = RandomForestClassifier(num_trees)\n",
    "    \n",
    "    return model, X_train, X_test\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PAvHDkQYK3g"
   },
   "outputs": [],
   "source": [
    "def finetuning(height, width, depth, classes):\n",
    "    # creating the base model of pre-trained VGG16 model\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape =(width, height,depth))\n",
    "\n",
    "    # freeze weights of  layers\n",
    "    base_model.trainable=False\n",
    "    \n",
    "    # Phase A\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # add the basemodel to your new Sequential Model\n",
    "    model.add(base_model)\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5-reB8KcvZ5"
   },
   "outputs": [],
   "source": [
    "def resnet():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yOmywxTE63O"
   },
   "outputs": [],
   "source": [
    "def learning_curves(history):\n",
    "\n",
    "  plt.style.use('ggplot')\n",
    "  plt.figure()\n",
    "  plt.plot(np.arange (0, num_epochs ), history.history['loss'], train_loss)\n",
    "  plt.plot(np.arange (0, num_epochs ), history.history['val_loss'], val_loss)\n",
    "  plt.plot(np.arange (0, num_epochs ), history.history['acc'], train_acc)\n",
    "  plt.plot(np.arange (0, num_epochs ), history.history['val_acc'], val_acc)\n",
    "  plt.title('Training Loss and Accuracy')\n",
    "  plt.xlabel('Epoch#')\n",
    "  plt.ylabel('Loss/Accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zV2ziH46zeF"
   },
   "outputs": [],
   "source": [
    "def visualization():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O42z-awAC5j7",
    "outputId": "9cfe2770-6b93-4e64-dddd-db259a6b3020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 37ms/step - loss: 2.1139 - accuracy: 0.2778 - val_loss: 1.7465 - val_accuracy: 0.3639\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "  # Setting the variables\n",
    "  NUM_EPOCHS = 50\n",
    "  height =32\n",
    "  width =32\n",
    "  depth=3\n",
    "  classes =10\n",
    "\n",
    "  # Loading the data\n",
    "  cifar = tf.keras.datasets.cifar10\n",
    "  # print(cifar)\n",
    "\n",
    "  # Splitting into train and test\n",
    "  (x_train , y_train),( x_test , y_test ) = cifar.load_data()\n",
    "\n",
    "  # print(x_train.shape) --50000\n",
    "  # print(y_train.shape) \n",
    "  # print(x_test.shape)-- 10000\n",
    "  # print(y_test.shape)\n",
    "\n",
    "  # plt.figure(1, figsize=(3, 3))\n",
    "  # plt.imshow(x_train.images[3], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "  # plt.show()\n",
    "\n",
    "  #  Normalize the data\n",
    "  x_train, x_test = x_train / 255.0, x_test / 255\n",
    "  # print(x_train[0])\n",
    "\n",
    "  # Models\n",
    "  choice = 3\n",
    "  if choice==1:\n",
    "    # Plain Dense Neural Network\n",
    "    model = plain_dense_neural_network(height, width, depth, classes)\n",
    "  \n",
    "  if choice ==2:\n",
    "     # Plain Dense Neural Network + Dropout\n",
    "    model = dense_neural_network_with_dropout(height, width, depth, classes)\n",
    "\n",
    "  if choice ==3:\n",
    "    # Simple VGG based Arch with Max Pool\n",
    "    model = simple_vgg_based_arch_with_maxpool(height, width, depth, classes)\n",
    "    pass\n",
    "\n",
    "  if choice ==4:\n",
    "    model = simple_vgg_based_arch_with_maxpool_and_dropout(height, width, depth, classes)\n",
    "    # Simple VGG +Max Pool +Dropout - observe the difference of learning curves between choice 2\n",
    "\n",
    "  if choice ==5:\n",
    "    # Transfer Learning - Feature Extraction after removing last FC layer\n",
    "    model, x_train, x_test = feature_extraction_using_pretrained_vgg16Model(height, width, depth, classes, x_train, x_test)\n",
    "    # Compile the Model\n",
    "  \n",
    "    # Fit the Model\n",
    "    model.fit(x_train , y_train)\n",
    "    results = model.predict(x_test)\n",
    "    print(metrics.accuracy_score(results, y_test))\n",
    "    \n",
    "  if choice ==6:\n",
    "    # Transfer Learning - Fine Tuning\n",
    "    model = finetuning(height, width, depth, classes)\n",
    "\n",
    "  if choice ==7:\n",
    "    # Ensembles\n",
    "    pass  \n",
    "\n",
    "  # Compile the Model\n",
    "  model.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  # Fit the Model\n",
    "  history = model.fit(x_train , y_train , NUM_EPOCHS, validation_data = (x_test , y_test))\n",
    "  \n",
    "  # Visualize through learning curve\n",
    "  learning_curves(history)\n",
    "  # Evaluate the Model\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjIrjegkoHHb"
   },
   "source": [
    "- Model 6 - Finetuning - 1000/1000 [==============================] - 625s 625ms/step - loss: 1.7445 - accuracy: 0.3856 - val_loss: 1.3832 - val_accuracy: 0.5236\n",
    "\n",
    "- Model 5- Feature Extraction - 0.5349\n",
    "\n",
    "- Model 4 - VGG with dropout - 1000/1000 [==============================] - 239s 239ms/step - loss: 1.8751 - accuracy: 0.3043 - val_loss: 1.2101 - val_accuracy: 0.5640\n",
    "\n",
    "- Model 3 - 1000/1000 [==============================] - 240s 239ms/step - loss: 1.5921 - accuracy: 0.4185 - val_loss: 1.0369 - val_accuracy: 0.6236\n",
    "\n",
    "- Model 6 again - 1000/1000 [==============================] - 638s 637ms/step - loss: 1.7500 - accuracy: 0.3843 - val_loss: 1.4055 - val_accuracy: 0.5139\n",
    "\n",
    "- Model 2 - Dense with dropout - 1000/1000 [==============================] - 39s 39ms/step - loss: 2.1506 - accuracy: 0.2351 - val_loss: 1.7668 - val_accuracy: 0.3649\n",
    "\n",
    "- Model 1 - Plain DNN - 1000/1000 [==============================] - 38s 37ms/step - loss: 2.1139 - accuracy: 0.2778 - val_loss: 1.7465 - val_accuracy: 0.3639\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvpwXOce7R9f"
   },
   "source": [
    "References:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQNHPmO9kELz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MultiModelApproaches - CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
